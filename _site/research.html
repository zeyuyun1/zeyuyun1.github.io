<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Zeyu Yun</title>

  
    
      <meta property="og:title" content="Research">
      <meta property="og:description" content="Short BioI'm currently a first year PhD Student in EECS, affliated with Redwood Center for Theoretical Neuroscience and BAIR at UC Berkeley, advised by Prof. Bruno Olshausen and Prof. Bin Yu. I also work closely with Prof. Yubei Chen at ...">
      <meta name="twitter:card" content="summary">
    
  

  <meta property="og:url" content="http://localhost:4000/research">

  <link rel="stylesheet" type="text/css" href="/assets/lib/normalize/normalize.css">
  <link rel="stylesheet" href="/assets/style.css">
  <link rel="stylesheet" href="/assets/custom.css">
</head>

<body>
  <div class="global-wrapper">
    <header class="site-header">
      <h1><a href="/">Zeyu Yun</a></h1>
      
      <section class="navigation">
  <nav>
    
      <ul class="nav-main nav-uppercase">
        
          
          
          <li class="active">
            <a href="/research">Research</a>
            
            </li>
        
          
          
          <li >
            <a href="/artwork">Gallery</a>
            
            </li>
        
          
          
          <li >
            <a href="/assets/cv.pdf">CV</a>
            
            </li>
        
          
          
          <li >
            <a href="/misc">MISC</a>
            
            </li>
        
      </ul>
    
  </nav>
</section>

    </header>
    <section class="site-content ">
      <!-- <link rel="stylesheet" href="/assets/custom.css"> -->
<h1>Short Bio</h1>
<section class="description">
I'm currently a first year PhD Student in EECS, affliated with <strong><a href="https://redwood.berkeley.edu/" target="_blank" class="publication-link">Redwood Center for Theoretical Neuroscience</a></strong> and <strong><a href="https://bair.berkeley.edu/" target="_blank" class="publication-link">BAIR</a></strong> at UC Berkeley, advised by Prof. <strong><a href="https://www.rctn.org/bruno/" target="_blank" class="publication-link">Bruno Olshausen</a></strong> and Prof. <strong><a href="https://binyu.stat.berkeley.edu/" target="_blank" class="publication-link">Bin Yu</a></strong>. I also work closely with Prof. <strong><a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a></strong> at UC Davis.
My research focuses on understanding the neural computation principle: the principle behinds the representation formed in neural networks. Previously, I was born and raised in Jinan and Qingdao, China. I came to US alone at aged 15 and 
graduated at Clovis North High School. I got both my bachelar (Math and CS) and master degree (EECS) in UC Berkeley. During my undergradute and master, I'm very fortunate to be advised by Prof. <strong><a href="https://www.rctn.org/bruno/" target="_blank" class="publication-link">Bruno Olshausen</a></strong> and Prof. <strong><a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a></strong>. 
</br>
I also spent a large amount of my time in NYC. Feel free to email me at <strong><a href="mailto:chobitstian@berkeley.edu" target="_blank" class="publication-link">chobitstian@berkeley.edu</a></strong>
if would love to chat about research online or grab a coffee in person.
</br>
</section>


<h1>Publications</h1>
<div class="publications">
  
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/urlost.png" alt="URLOST: Unsupervised representation learning without stationarity or topology">
        </div>
        <div class="post-content">
          <h2 class="post-title">URLOST: Unsupervised representation learning without stationarity or topology</h2>
          
          
          
          
          <div class="post-authors"><strong>Zeyu Yun</strong>, <a href="https://juexzz.github.io/" target="_blank" class="publication-link">Juexiao Zhang</a>, <a href="https://scholar.google.com/citations?user=WLN3QrAAAAAJ&hl=en" target="_blank" class="publication-link">Yann LeCun</a>, and <a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a></div>

          
            <a class="publication-link" href="https://arxiv.org/abs/2310.04496">[arXiv]</a>
          
          
          
          <div class="post-venue">ICLR 2025</div>
          
          <div class="description">
            We developed an unsupervised learning model for generic high dimensional data. The model demonstrated exceptional performance across diverse data modalities from neural recording to gene expression.
          </div>
        </div>
      </div>
    
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/factorize.png" alt="Predictive and Invariant Representations via Motion and Form Factorization in Natural Scenes">
        </div>
        <div class="post-content">
          <h2 class="post-title">Predictive and Invariant Representations via Motion and Form Factorization in Natural Scenes</h2>
          
          
          
          
          <div class="post-authors"><strong>Zeyu Yun</strong>, Christopher Kymn, Galen Chuang, <a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a>, <a href="https://www.rctn.org/bruno/" target="_blank" class="publication-link">Bruno Olshausen</a></div>

          
          
          
          <div class="post-venue">Cosyne 2025</div>
          
          <div class="description">
            We applied the principles of sparsity and temporal consistency to build a factorizable representations for natural scenes. 
          </div>
        </div>
      </div>
    
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/denoising.png" alt="Denoising for Manifold Extrapolation">
        </div>
        <div class="post-content">
          <h2 class="post-title">Denoising for Manifold Extrapolation</h2>
          
          
          
          
          <div class="post-authors"><strong>Zeyu Yun</strong>, Galen Chuang, Derek Dong, <a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a></div>

          
          
          
          <div class="post-venue">NeurIPS SciForDL workshop 2024</div>
          
          <div class="description">
            We applied the principles of sparsity and temporal consistency to build a factorizable representations for natural scenes. 
          </div>
        </div>
      </div>
    
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/retina.gif" alt="Natural retinal cone distributions emerge from optical and neural limits to vision">
        </div>
        <div class="post-content">
          <h2 class="post-title">Natural retinal cone distributions emerge from optical and neural limits to vision</h2>
          
          
          
          
          <div class="post-authors"><a href="https://yazhou-z.github.io/" target="_blank" class="publication-link">Yazhou Zhao</a>*, <strong>Zeyu Yun</strong>*, Ruichang Sun, and <a href="https://d-bi.github.io/" target="_blank" class="publication-link">Dasheng Bi</a></div>

          
          
          
          <div class="post-venue">VSS 2024</div>
          
          <div class="description">
            We model visual system with a chromatic aberration constrained optical simulation and designed a learnable cone mosaic sampling. We show that the modelâ€™s emerged cone mosaic resembles a cone mosaic found in humans, when optimized for both spatial acuity and color acuity.
          </div>
        </div>
      </div>
    
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/smt.png" alt="Minimalistic unsupervised representation learning with the sparse manifold transform">
        </div>
        <div class="post-content">
          <h2 class="post-title">Minimalistic unsupervised representation learning with the sparse manifold transform</h2>
          
          
          
          
          <div class="post-authors"><a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a>, <strong>Zeyu Yun</strong>, <a href="https://people.eecs.berkeley.edu/~yima/" target="_blank" class="publication-link">Yi Ma</a>, <a href="https://www.rctn.org/bruno/" target="_blank" class="publication-link">Bruno Olshausen</a>, and <a href="https://scholar.google.com/citations?user=WLN3QrAAAAAJ&hl=en" target="_blank" class="publication-link">Yann LeCun</a></div>

          
            <a class="publication-link" href="https://arxiv.org/pdf/2103.15949.pdf">[arXiv]</a>
          
          
          
          <div class="post-venue">ICLR 2023 (spotlight)</div>
          
          <div class="description">
            Constructed a two-layer interpretable unsupervised learning model based on principles from neural computation. The model remains competitive with deep learning methods. 
          </div>
        </div>
      </div>
    
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/vis.png" alt="Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors">
        </div>
        <div class="post-content">
          <h2 class="post-title">Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors</h2>
          
          
          
          
          <div class="post-authors"><strong>Zeyu Yun</strong>*, <a href="https://yubeichen.com/" target="_blank" class="publication-link">Yubei Chen</a>*, <a href="https://www.rctn.org/bruno/" target="_blank" class="publication-link">Bruno Olshausen</a>, <a href="https://scholar.google.com/citations?user=WLN3QrAAAAAJ&hl=en" target="_blank" class="publication-link">Yann LeCun</a></div>

          
            <a class="publication-link" href="https://arxiv.org/pdf/2103.15949.pdf">[arXiv]</a>
          
          
            <a class="publication-link" href="https://transformervis.github.io/transformervis/">[Demo]</a>
          
          
          <div class="post-venue">NAACL DeeLIO Workshop 2021</div>
          
          <div class="description">
            We used sparse coding to visualize Large Language Models (LLMs). By adopting neural computation principle, we greatly improve the interpretability of LLMs. Our result implies  LLMs compute in a manner akin to the human brain, where it builds representations to predict upcoming language at multiple levels of abstraction.
          </div>
        </div>
      </div>
    
  
    
  
</div>

<h1>Work under preperation</h1>
<div class="publications">
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <div class="post-container">
        <div class="post-thumb">
          <img src="/assets/images/research/stability.png" alt="Stability-driven design and denoising of sparse autoencoders">
        </div>
        <div class="post-content">
          <h2 class="post-title">Stability-driven design and denoising of sparse autoencoders</h2>
          
          
          
          <!--  -->
          <div class="post-authors"><strong>Zeyu Yun</strong> and <a href="https://abbasilab.org/" target="_blank" class="publication-link">Reza Abbasi-Asl</a></div>
          
          
          
          <div class="post-venue">in preparation</div>
          
          <div class="description">
            We proposed a stability-driven autoencoder for unsuperised learning. The method is used for extracting gene expression patterns.
          </div>
        </div>
      </div>
    
  
</div>


    </section>
    <footer class="site-footer">
  <p class="copyright">
    
      &copy; 2019-2024.
      <a href="mailto:chobitstian@berkeley.edu">Zeyu Yun</a>
      ALL RIGHTS RESERVED.
    
  </p>
</footer>

  </div>
  <script type="text/javascript" src="/assets/custom.js"></script>
</body>
</html>
